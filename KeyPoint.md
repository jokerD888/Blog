# KeyPoint

- 首先这里介绍的模型，其目标是接受一段文本，预测下一个词。这里介绍的注意力指的是自注意力（self-attention)。自注意力（Self-Attention）之所以被称为“自”，是因为它处理的是同一个序列内部的信息，即一个序列中的每个元素都能够关注到该序列中其他所有元素。这种机制允许模型在处理某个位置的元素时，能够同时考虑到整个序列内其他位置的相关信息。这里的“自”体现了信息来源于自身序列的特点。
- Transformer：头端是嵌入矩阵（将token转化为高维向量），中间层是Attention和MLP的层层堆叠（GPT-3堆叠96次），尾端是解嵌入矩阵（用最后一个embedding做预测，输出每个token的概率）
- 使用softmax将数列转换为概率时，给指数加个分母T（temperature），当T较大时，会给低值赋予更多权重，使得分布更加均匀，当T较小时，那么较大的数占据优势，特别的，当T为0时，意味着所有权重都给到最大值。
- 高维空间的方向可以对应到某一语义
- Transformer的目标是逐步调整这些embedding，使他们不仅仅编码单个token，还能够融入更加丰富的上下文含义。
- 训练好的注意力模块能计算出，需要给初始的泛型嵌入加个什么向量，才能把它移动到上下文对应的具体方向上。注意力模块不仅精细化了一个词的含义，还允许模型相关传递这些嵌入向量所蕴含的信息。
- 如果模型要准确预测下一个词，该序列的最后一个嵌入向量必须经过所有注意力模块的更新，以包含远程单个词的信息量。也就是要设法编码整个上下文窗口中与预测下一个词相关的所有信息。
- 查询向量(Q)：由矩阵Wq和嵌入向量E，Wq * E = Q。代表了当前要查询的信息。同时将嵌入空间中的词映射到低维的查询空间中。
- 键向量 (K)：由矩阵Wk和嵌入向量E，Wk * E = K。可以把“键”视为想要回答“查询”。同样的将嵌入空间中的词映射到低维的键空间中。
- 当键与查询的方向相齐时，就能认为他们相匹配。为了衡量每个键与每个查询的匹配程度，要计算所有可能的键-查询对之间的点积。然后对于询问与每个查询的结果除以键-查询空间的维度的平方根（为了数值稳定性）使用softmax函数做归一化。
- 同时为了避免后方的token影响前方位置的token，这些点在矩阵中会全部变为负无穷再做上面的softamx，这一过程称为masking（掩码）。有的注意力机制不使用掩码。
- QK矩阵大小为上下文长度的平方，这就是为何上下文长度会成为大语言模型的巨大瓶颈。
- 值向量 (V)：计算出上面矩阵后，就能让模型推断出每个词与其他哪些词有关，那么接下来就更新嵌入向量，把各个词的信息传递给与之相关的词。通过值矩阵，将它乘以前面那个词的embedding，得到的结果就是值向量，Wv * E_(i-1) = V。这个值就是你要个后词的embedding所加的向量。值向量与嵌入向量处于同一个高维空间。值矩阵乘以一个词的嵌入向量可以理解为：如果这个词需要调整目标词的含义，要反映这一点，得对目标词的embedding加入什么向量呢？
- 将值矩阵与所有嵌入向量E相乘就可以得到一系列值向量，同时对于每个词的那一列需要给每个值向量乘以该列对应的权重（这个权重就是QK矩阵经过softmax后的输出），然后对该列进行加和，然后再加入到原始的嵌入向量中，就得到一个更加精准的向量，编码了更丰富的上下文信息。对其他嵌入向量做同样的操作后就得到了一系列更加精准的向量。
- 上面说的是单注意力头，而Transformer中的注意力模块由多头注意力组成，大量并行地执行上述单注意力头的操作（例如，GPT-3每个模块内使用96个注意力头），而每个头都有不同的键，查询，值矩阵，不同的头产生不同的注意力模式。然后对于某个词，将各个头给出的变化量加到初始嵌入向量，最后便得到了更为精准的嵌入向量。
- 嵌入矩阵、Attention层、解嵌入矩阵的参数大约共占整个Transformer参数量的三分之一，剩余的三分之二则是MLP层的参数。尽管关于事实存储的完整机制尚未揭示，但有一条普适的高级结论：事实似乎存储在神经网络中的MLP模块中。
- 若一个编码了“名字迈克尔”“姓氏乔丹”的向量流入MLP，那么经过一系列计算，能够输出包含“篮球”方向的向量，再将其原向量相加，得到输出向量。
- MLP模块：该过程的第一步是将输入向量与一个超大矩阵（升维投影矩阵）相乘，可以设想矩阵的每一行作为一个向量，可以设想第一行恰好为假想存在的“名字迈克尔”这一方向，那么输出向量的第一个分类为1（若向量编码了“名字迈克尔”）或为0或负数（没编码“名字迈克尔”）。可以想象其他行也在并行的提问各种问题，探查嵌入向量的其他各类特征，同时还会加上一列偏置向量Bias。通过这个矩阵（GPT-3是（4×12288）49152×12288）将向量映射到更高维的空间。该操作是线性的，但语言是高度非线性的，“迈克尔.乔丹”的测量值可能被“迈克尔.XX"或”XX.乔丹“所影响，所以需要第二步：通过一个简单的非线性函数ReLU或GELU后，得到的结果就会很干净。接下来第三步和第一步很相似，也是先左乘一个超大矩阵（降维投影矩阵），然后加上一个偏置项，此时，输出向量的维数降回到嵌入空间的维数，这个矩阵中的列能够说明若对应的神经元被激活，则将在结果添加什么信息，完成之后便能够输出包含”篮球“方向的向量，最后再将其原向量相加，得到输出向量。请注意，这个过程对所有向量并行进行，那么就是矩阵乘矩阵了。
- 然而，证据表明，单个神经元几乎不会代表像”迈克尔.乔丹“这样的单一特征，这与如今可解释性研究中的Superposition(叠加)概念有关，这个假设有助于解释为什么模型难以解释，以及为什么模型扩展性出奇的好。其基本思想是：在一个N维空间中，若是想用一堆正交基表示各种不同的特征，这样在一个方向添加向量就不会影响其他反向，那么最多能容纳N个向量。但若放宽一些限制，比如允许这些特征对应的向量并不完全垂直，而是几乎垂直，比如89°~91°之间。约翰逊-林登斯特劳斯引理的一个结果是，能在空间中塞进几乎垂直的向量数量，随维数增加指数增长。这对大语言模型意义重大，能将相互独立的概念与几乎垂直的向量相关联而受益，意味着能在有限的空间维数中存储数量多得多的各种概念，这可能部分解释了为什么模型性能随规模扩大而提升显著。
- 升维投影矩阵和降维投影矩阵是MLP中的主要参数，而这样的MLP在GPT-3中共有96层，这些参数加起来约有1160亿，占神经网络的三分之二，而将前面的注意力模块，嵌入矩阵，解嵌入矩阵加起来就能得到GPT-3宣传的1750亿个总参数量。

------

- 自回归模型：对见过的数据建模，即它通过使用过去的时间点来预测未来值。
- 马尔可夫假设：假设当前数据只跟T个过去时间点相关，即在一个序列中只考虑某个长度为T的时间跨度。最直接的好处是参数的总数量不变，坏处是可能存在跨度为T之外的有效信息无法观测到。
- 潜变量模型：保留过去观察的一些总结h_t，并且同时更新x_hat_t和总结h_t。总的来说就是使用潜变量来概括历史信息。
- 为了训练语言模型，我们需要计算单词的概率， 以及给定前面几个单词后出现某个单词的条件概率。 这些概率本质上就是语言模型的参数。
- 当序列（理解为词组）很长时，因为文本量不够大，可能导致某些序列（词组）出现的次数很小，甚至没有出现过。
- N元语法：使用马尔可夫假设可以缓解上面问题。例如处理一个序列（词组）时一元语法：就变为了各个词直接是独立的，二元语法：则当前词只与前面的一个词有关系，三元语法：当前词只与前面的两个词有关系。这样就可以处理长序列了。
- 若只有100个词的话，二元语法就需要10000个二元组，三元语法需要1000000个三元组。但得益于语言的结构性，再做个低频过滤，实际上的元组数量其实并没有那么大。可以发现单词的频率是满足齐普夫定律的。所以元组是可以稍微做长一些的。
- RNN的每一层可以看作是多个隐藏神经元组成，类似MLP中的隐藏层，不同的是RNN的隐藏状态不仅依赖当前输入，还依赖前一个状态的隐藏状态。
- 困惑度：平均交叉熵，可以看作n次分类。困惑度是对平均交叉熵做了个指数，1表示完美，无穷大是最差情况。
- 梯度裁剪：迭代中计算多个时间步上的梯度，在方向传播过程中会产生对应长度的矩阵乘法链，导致数值不稳定。梯度裁剪能有效预防梯度爆炸，具体来说，入股梯度长度超过θ，那么拖影会长度θ。
- 做RNN时候处理不了太长序列，因为当时间太长时，隐藏状态累计了太多东西，对于前面的信息不太好抽取信息了。

------

# GRU（Gated Recurrent Unit）详解

GRU（Gated Recurrent Unit）是一种改进的**循环神经网络（RNN）**，专门为了解决传统RNN中的一些问题而设计，尤其是**梯度消失**和**长距离依赖**的问题。GRU通过**门控机制**来控制信息的流动，使得网络能够更好地记住重要信息，丢弃不重要的信息。

### 1. GRU的结构
GRU的结构与传统RNN相比有一些关键的改进。传统RNN每个时间步的隐藏状态是单一的，而GRU引入了**两个门**来控制信息流动：**更新门**和**重置门**。

- **更新门（Update Gate）**: 控制从前一个时间步传递过来的信息有多少需要保留，多少需要更新。这类似于LSTM中的遗忘门和输入门的结合。它能够判断当前时刻的信息是否重要，从而决定保留多少之前的记忆。

- **重置门（Reset Gate）**: 控制是否忘记前一个时间步的隐藏状态，也就是允许网络“重置”隐藏状态。如果重置门接近0，则当前时刻会忽略之前的记忆，只依赖当前输入进行计算。

### 2. GRU的核心公式
GRU的运算可以分为以下几步：

- **更新门**决定保留多少过去的隐藏状态：
  $$
  z_t = \sigma(W_z \cdot [h_{t-1}, x_t])
  $$
  其中，$z_t$ 是更新门的输出，$ W_z $ 是权重矩阵，$ h_{t-1} $ 是前一个时间步的隐藏状态，$ x_t $ 是当前时间步的输入，$ \sigma $ 是sigmoid激活函数。

- **重置门**决定前一时刻的信息是否被遗忘：
  $$
  r_t = \sigma(W_r \cdot [h_{t-1}, x_t])
  $$
  其中， r_t  是重置门的输出，$ W_r $ 是重置门的权重矩阵。

- **候选隐藏状态** $ \tilde{h}_t $ 计算如下，它结合当前的输入和过去的信息（在重置门的调节下）：
  $$
  \tilde{h}_t = \tanh(W_h \cdot [r_t \ast h_{t-1}, x_t])
  $$
  这里 $ \ast $ 表示元素逐项相乘（Hadamard乘积），即只保留前一个隐藏状态中被重置门选中的部分。

- **最终的隐藏状态** $ h_t $ 是通过更新门来在之前的隐藏状态 $ h_{t-1} $ 和新的候选隐藏状态 $ \tilde{h}_t $ 之间进行选择：
  $$
  h_t = z_t \ast h_{t-1} + (1 - z_t) \ast \tilde{h}_t
  $$
  这个公式可以理解为，更新门 $ z_t $ 决定了多少过去的记忆 $ h_{t-1} $ 被保留，而 $ 1 - z_t $ 决定了多少当前的新信息 $ \tilde{h}_t $ 会替代旧的信息。

极端情况z=0,r=1，就是RNN，前一时刻的隐藏状态被用于候选状态的计算，但被完全抛弃，最终隐藏状态只依赖当前输入。z=1,r=0,前一时刻的隐藏状态完全保留，当前输入不会对隐藏状态产生影响。

### 3. GRU的优势
GRU与传统RNN相比有很多优势，甚至与LSTM相比也是一种更简洁、高效的替代方案：

- **简化结构**：相比LSTM，GRU结构更简单，少了一个门（GRU有两个门，LSTM有三个门）。这使得GRU计算开销相对较低，同时还能提供与LSTM类似的性能。
  
- **缓解梯度消失问题**：传统RNN在处理长时间依赖时容易出现梯度消失，导致模型无法学习到长序列中的依赖关系。GRU通过门控机制有效解决了这一问题，能够更好地保留重要的长时间依赖信息。

- **更快的训练速度**：由于GRU的门控机制比LSTM简单，它在某些任务上能够实现更快的训练速度，同时性能不会下降太多。

- **高效性**：在处理短期依赖时，GRU的表现通常与LSTM相似，但因为其结构简化，实际应用中GRU往往在计算成本上更具优势。

### 4. GRU的应用场景
GRU广泛应用于需要处理序列数据的场景中，常见的任务包括：

- **自然语言处理（NLP）**：如机器翻译、文本生成、情感分析等任务，GRU可以很好地处理文本中的上下文依赖。
- **时间序列预测**：如股票价格预测、天气预报、传感器数据分析等，GRU擅长捕捉时间序列中的模式。
- **语音识别**：处理音频数据，GRU能够学习到音频信号的序列特征。

PyTorch中LSTM的实现

```python
import torch
import torch.nn as nn

# 定义GRU层
# input_size: 输入特征的维度
# hidden_size: 隐藏层的神经元个数
# num_layers: GRU的层数
gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2)

# 创建输入数据 (序列长度, batch_size, 输入维度)
input_data = torch.randn(5, 3, 10)  # 序列长度为5，batch_size为3，输入维度为10

# 初始化隐藏状态 (num_layers, batch_size, hidden_size)
h0 = torch.randn(2, 3, 20)  # GRU没有记忆单元，只需初始化隐藏状态

# 前向传播
output, hn = gru(input_data, h0)

# 输出结果
print(output.shape)  # (序列长度, batch_size, hidden_size)
print(hn.shape)      # (num_layers, batch_size, hidden_size)
```

### 5. GRU与LSTM的比较

| **特性**         | **GRU**                                    | **LSTM**                             |
| ---------------- | ------------------------------------------ | ------------------------------------ |
| **门的数量**     | 2个（更新门和重置门）                      | 3个（输入门、遗忘门、输出门）        |
| **隐藏状态更新** | 更加简化的隐藏状态更新机制                 | 更复杂的单元状态和隐藏状态更新机制   |
| **记忆能力**     | 能够处理长短期依赖，适合多种序列数据       | 尤其适合长时间依赖的序列数据         |
| **计算效率**     | 结构较简单，训练速度更快，计算效率更高     | 结构复杂，计算开销较大               |
| **适用场景**     | 大多数任务中表现优异，尤其是中短期依赖问题 | 更适合处理长时间依赖且数据复杂的任务 |

### 总结
GRU是RNN的改进版本，通过引入门控机制，在序列数据处理中能够更好地处理长距离依赖和短期依赖问题。相比LSTM，GRU结构更简化，计算效率更高，因此在许多应用中，它是LSTM的高效替代品。

# LSTM（长短期记忆网络）

LSTM（Long Short-Term Memory，长短期记忆网络）是一种特殊的 **循环神经网络（RNN）**，用来解决普通RNN在长序列中表现不佳的问题。普通RNN因为在反向传播过程中存在**梯度消失**或**梯度爆炸**的问题，难以捕捉长时间的依赖关系，而LSTM通过引入**记忆单元**和**门机制**，可以更好地处理长期依赖。

## LSTM结构

LSTM的核心在于其特殊的单元结构，它由几个**门（Gate）**组成，这些门控制信息在网络中的流动，决定哪些信息应该保留，哪些应该丢弃。具体来说，LSTM单元包括：

1. **遗忘门（Forget Gate）**  
   决定应该忘记多少过去的状态。该门通过输入当前的输入 $$x_t$$ 和上一个隐藏状态 $$h_{t-1}$$ 计算得到：
   $$
   f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)
   $$
   其中，$$W_f$$ 是权重矩阵，$$b_f$$ 是偏置，$$\sigma$$ 是激活函数（通常为 sigmoid 函数，输出值在 [0, 1] 之间，表示遗忘的比例）。

2. **输入门（Input Gate）**  
   控制当前的输入 $$x_t$$ 对记忆单元状态的影响。该门由两部分组成：

   - **更新门**决定新信息的更新量：
     $$
     i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)
     $$
   - **候选记忆单元**，生成一个新的候选值 $$\tilde{C_t}$$：
     $$
     \tilde{C_t} = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)
     $$
     输入门和候选记忆单元共同决定了新的记忆内容。

3. **记忆单元状态更新**  
   记忆单元的状态 $$C_t$$ 是LSTM中保存长期信息的部分，它会基于遗忘门和输入门更新：
   $$
   C_t = f_t \cdot C_{t-1} + i_t \cdot \tilde{C_t}
   $$
   这一步将旧记忆和新记忆结合起来，更新到新的记忆状态。

4. **输出门（Output Gate）**  
   决定当前时刻的输出以及下一个隐藏状态 $$h_t$$。输出门通过当前输入和上一个隐藏状态计算：
   $$
   o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)
   $$
   然后计算当前的隐藏状态 $$h_t$$：
   $$
   h_t = o_t \cdot \tanh(C_t)
   $$
   其中，$$C_t$$ 是通过前面的记忆单元状态更新得到的。

## LSTM的运行过程

在每一个时间步 $$t$$，LSTM执行以下步骤：

1. 读取当前的输入 $$x_t$$ 和上一个时间步的隐藏状态 $$h_{t-1}$$。
2. 通过遗忘门计算需要丢弃多少过去的信息。
3. 通过输入门和候选记忆单元决定新的记忆更新。
4. 更新当前记忆单元的状态 $$C_t$$，结合遗忘门和输入门的影响。
5. 通过输出门计算新的隐藏状态 $$h_t$$，并输出该状态。

## LSTM的优势

- **解决了梯度消失问题**：LSTM通过引入了长时间的记忆机制和门控机制，可以有效捕捉长距离依赖，解决了普通RNN在长序列中的梯度消失问题。
- **灵活的记忆能力**：LSTM能够选择性地遗忘或记住信息，这使得它在许多序列处理任务中表现优异，特别是在自然语言处理、时间序列预测、语音识别等任务中表现尤为突出。

## PyTorch中LSTM的实现

在PyTorch中，LSTM已经被封装好了，可以直接使用：

```python
import torch
import torch.nn as nn

# 定义LSTM层
lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)

# 创建输入数据 (序列长度, batch_size, 输入维度)
input_data = torch.randn(5, 3, 10)  # 长度为5的序列，batch_size为3，输入维度为10

# 初始化隐藏状态 (num_layers, batch_size, hidden_size)
h0 = torch.randn(2, 3, 20)  # 隐藏状态
c0 = torch.randn(2, 3, 20)  # 记忆单元状态

# 前向传播
output, (hn, cn) = lstm(input_data, (h0, c0))

print(output.shape)  # (序列长度, batch_size, hidden_size)
print(hn.shape)      # (num_layers, batch_size, hidden_size)
print(cn.shape)      # (num_layers, batch_size, hidden_size)
```

# 深层循环神经网络（Deep Recurrent Neural Network, DRNN）

深层循环神经网络是通过堆叠多层RNN单元（例如LSTM或GRU）来增强模型的学习能力。每一层的RNN输出都会作为下一层的输入，从而形成深层网络结构。相比单层RNN，深层RNN能够捕捉更复杂的序列模式和层次化的特征表达。

#### 特点：

- **多层结构**：多个RNN单元层堆叠而成，逐层抽象特征。
- **增强表达能力**：可以提取和学习序列数据中的更复杂模式。
- **适用于复杂任务**：如语音识别、语言建模等需要更高表达能力的任务。

#### 示例结构：

假设有3层LSTM网络：

1. 第一层接受原始输入序列并输出一个隐藏状态序列。
2. 第二层接受第一层的输出作为输入，生成新的隐藏状态序列。
3. 第三层再处理第二层的输出，生成最终的输出序列。

这种深层结构能够更好地理解序列中的长短期依赖关系。

# 双向循环神经网络（Bidirectional Recurrent Neural Network, BRNN）

双向循环神经网络是对传统RNN的扩展，它通过同时在正向和反向两个方向上处理输入序列。具体来说，BRNN有两组独立的RNN单元：

- **正向RNN**：从序列的起点到终点依次处理数据。
- **反向RNN**：从序列的终点到起点逆向处理数据。

双向RNN结合了正向和反向的信息，在某些任务（如序列标注、机器翻译等）中，序列的上下文都可能对当前时刻有影响，因此这种双向处理可以捕捉到更丰富的信息。

#### 特点：

- **前向与后向结合**：通过双向RNN捕获过去和未来的上下文信息。
- **适用于对上下文要求较高的任务**：例如语音识别、命名实体识别、机器翻译等任务。

#### 工作过程：

1. 输入序列被正向RNN从左到右处理，得到一个隐藏状态序列。
2. 同时，输入序列被反向RNN从右到左处理，得到另一个隐藏状态序列。
3. 两个方向的隐藏状态结合起来，生成每个时间步的最终输出。

### 总结

- **深层RNN（DRNN）**：通过堆叠多层RNN单元来提升模型的表达能力，适合复杂的序列任务。
- **双向RNN（BRNN）**：在正向和反向同时处理输入，利用上下文的完整信息，适合需要前后文信息的任务。

------

# DeepLab系列

DeepLab系列是谷歌提出的一系列用于图像**语义分割**的算法，它们在处理**不同分辨率**的图像特征、保持空间精度和捕获多尺度上下文方面表现出色。DeepLab系列主要包括以下几个版本：DeepLabv1、DeepLabv2、DeepLabv3 和 DeepLabv3+。

## SPP（Spatial Pyramid Pooling，空间金字塔池化）

在经典的卷积神经网络中，输入图像通常需要被缩放到固定大小才能通过**全连接层**进行分类（因为全连接层的权重矩阵W是一个固定值）。然而，现实中的图像具有多种不同的分辨率和尺度，强制缩放可能会导致图像信息的丢失，尤其是对象的形状和比例。因此，SPP提出了一种方法，在不改变输入图像大小的情况下，通过多尺度池化获取固定长度的特征表示。

### 主要原理

SPP 在卷积层输出的特征图上应用多个尺度的池化操作，从而生成不同尺度下的特征表示。它主要分为以下几个步骤：

1. **特征提取**：首先，图像通过卷积层，输出一个大小为 `h × w × d` 的特征图（其中 `h` 和 `w` 是特征图的高度和宽度，`d` 是通道数）。
2. **空间金字塔池化**：在这个特征图上，SPP 使用不同尺度的窗口进行池化操作。例如，使用 1×1、2×2、4×4 等不同尺寸的窗口分别进行池化。这些池化窗口将整个特征图划分为不同的网格区域，在每个区域内通过最大池化或平均池化得到特征值。
3. **固定长度的特征向量**：每个尺度的池化操作都会输出一个固定长度的特征向量。然后将这些特征向量连接起来，最终形成一个固定长度的向量，无论输入图像的大小是多少。
4. **全连接层**：得到的固定长度特征向量可以直接输入全连接层进行分类任务。

## ASPP（Atrous Spatial Pyramid Pooling，空洞空间金字塔池化）

ASPP通过在特征图上应用不同的空洞率（dilation rate）来调整卷积的感受野，类似于金字塔池化（SPP），它能够从不同尺度上捕捉特征信息。而与传统池化不同的是，ASPP采用空洞卷积以扩大感受野，而不会增加卷积核的参数或损失分辨率。

### ASPP的结构

ASPP模块通常由多个不同空洞率的空洞卷积组成，它们并行操作在同一个特征图上，分别捕捉不同尺度的上下文信息。ASPP的结构可以分为以下几部分：

1. **不同空洞率的空洞卷积**： ASPP通过并行设置不同的空洞率（例如1, 6, 12, 18），来处理特征图。每个卷积核感受野不同，因此它们能从不同的尺度提取图像中的信息。
2. **全局池化**： 为了捕捉更广泛的上下文信息，ASPP模块还会添加一个全局平均池化分支，将整个图像的全局信息汇入到网络中，增强对全局上下文的感知。
3. **特征融合**： 所有空洞卷积和全局池化的输出会被连接起来，并通过1×1卷积进行融合。随后，ASPP会应用批归一化（Batch Normalization）和非线性激活函数（如 ReLU）以增强模型的表达能力。
4. **上采样**： 在语义分割中，为了得到与输入图像相同大小的输出，ASPP的输出通常需要进行上采样（例如通过双线性插值）以恢复原始分辨率。

## 1. **DeepLabv1：基于空洞卷积的提升**

DeepLabv1是DeepLab系列的第一个版本，主要解决的是在全卷积网络（Fully Convolutional Networks, FCN）中，由于多次池化操作导致的分割图像分辨率下降的问题。

#### 核心创新：**空洞卷积（Atrous Convolution）**

- **空洞卷积的定义**：空洞卷积通过在标准卷积核之间插入“空洞”（即跳过某些像素），来增大感受野，而不增加参数量。通过这种方式，网络可以在不增加计算量的情况下捕获更大的上下文信息。
- **作用**：空洞卷积允许网络在不降低分辨率的情况下捕捉到更大的感受野，这有助于更好地处理全局信息，同时保持局部细节。

在DeepLabv1中，作者将空洞卷积引入到最后的卷积层，以在保持较高分辨率的同时捕捉到更丰富的上下文信息。

## 2. **DeepLabv2：多尺度上下文的提升**

DeepLabv2在DeepLabv1的基础上，进一步引入了多尺度特征融合的机制，以捕获不同尺度的上下文信息。这个版本中，主要的创新是引入了**空洞空间金字塔池化（ASPP，Atrous Spatial Pyramid Pooling）**模块。

#### 核心创新：**ASPP**

- **ASPP的作用**：ASPP模块通过在不同空洞率（dilation rates）下对输入特征图进行卷积，来捕捉不同尺度的上下文信息。不同的空洞率对应着不同的感受野，从而使模型能够在不同的尺度上捕获上下文信息。
- **多尺度融合**：ASPP将不同空洞率的卷积结果进行融合，从而有效结合了多尺度信息。这使得模型能够同时关注图像中的大尺度全局信息和小尺度局部细节，从而提升分割效果。

DeepLabv2因此在处理具有复杂背景或需要捕捉多尺度信息的场景时具有更好的表现。

## 3. **DeepLabv3：增强的空间金字塔池化**

DeepLabv3在DeepLabv2的基础上进行了进一步的改进，主要在ASPP模块和残差网络（ResNet）上做了增强。此外，DeepLabv3取消了全连接层并全卷积化，提升了模型的效率和表现。

#### 核心创新：**改进的ASPP和全卷积化**

- **改进的ASPP**：DeepLabv3中的ASPP模块不仅使用了空洞卷积，还加入了全局平均池化（Global Average Pooling）作为一种全局上下文信息的补充。通过融合全局上下文，模型可以更好地理解图像的整体结构。
- **可变空洞率**：DeepLabv3允许在不同的卷积层中使用可变的空洞率（dilated convolution），从而在不同层次上动态调整感受野，进一步提升多尺度信息的提取能力。
- **全卷积化**：DeepLabv3抛弃了之前版本中的全连接层，完全依赖卷积操作，从而大大提高了分割结果的分辨率和模型的计算效率。

DeepLabv3也通过与残差网络（ResNet）的结合，增强了网络的特征提取能力，使得模型在各种语义分割任务中都能获得更好的表现。

## 4. **DeepLabv3+：解码器模块的引入**

DeepLabv3+是DeepLab系列中的最新版本，它在DeepLabv3的基础上引入了解码器（Decoder）模块，从而显著提升了模型在边界区域的表现。

#### 核心创新：**编码器-解码器结构**

- **编码器（Encoder）**：DeepLabv3+的编码器部分与DeepLabv3类似，使用空洞卷积和ASPP模块来提取特征。编码器的任务是从输入图像中提取多尺度特征。
- **解码器（Decoder）**：解码器模块的任务是恢复分割结果的空间分辨率，尤其是边界信息的恢复。DeepLabv3+通过将高分辨率的低层特征与编码器提取的高层特征进行融合，再经过几层卷积来逐步恢复原始分辨率的分割结果。

引入解码器的目的是解决在DeepLabv3中分割图像边缘模糊的问题。解码器有效结合了深层次的语义信息与浅层次的空间细节信息，从而显著提升了分割图像的边界质量。

## 5. **DeepLab系列的性能提升总结**

每个DeepLab版本都针对特定的问题进行了改进：

- **DeepLabv1**：通过空洞卷积解决了池化导致的分辨率下降问题。
- **DeepLabv2**：引入ASPP模块，提升了对多尺度信息的捕捉能力。
- **DeepLabv3**：进一步增强了ASPP模块和空洞卷积的使用，同时全卷积化提升了计算效率。
- **DeepLabv3+**：引入了解码器模块，提升了对边界细节的恢复能力，特别是在复杂背景下的分割精度。

## 6. **DeepLab的应用场景**

DeepLab系列广泛应用于图像语义分割任务，特别是在需要像素级分类的场景，如：

- **自动驾驶**：用于道路场景中的车道线、行人、车辆等目标的精准分割。
- **医学图像处理**：用于如CT、MRI等医学图像中的器官或病灶分割。
- **遥感影像分析**：用于卫星图像中地物目标的分割，如建筑、河流、植被等的识别。

DeepLab系列由于其优异的分割性能和强大的多尺度特征提取能力，已成为语义分割任务中最常用的模型之一。

### 总结

DeepLab系列通过引入空洞卷积、ASPP、多尺度上下文融合、全卷积化以及编码器-解码器结构，不断提升语义分割的精度和效率。它在捕捉多尺度上下文信息的同时，保持了图像的高分辨率，解决了传统卷积神经网络在语义分割任务中存在的许多问题。

------

## `seq2seq`（sequence-to-sequence）

`seq2seq`（sequence-to-sequence）是一类用于处理序列数据的深度学习模型，特别适合解决输入和输出都是序列的问题，如机器翻译、文本摘要、对话系统等任务。其核心思想是使用一个神经网络将输入序列编码成一个固定大小的表示，然后使用另一个神经网络从该表示生成输出序列。

### 模型结构

1. **编码器（Encoder）**
   - 编码器负责接收输入序列（如一段文本）并将其转换为一个上下文向量（也称为“上下文”或“中间表示”），该向量包含了输入序列的全部信息。
   - 编码器通常是一个RNN（如LSTM或GRU）或是基于Transformer结构的网络。对于每个输入步骤，编码器生成一个隐藏状态，最终的隐藏状态或隐藏状态的集合用于生成上下文向量。
2. **解码器（Decoder）**
   - 解码器从编码器传递过来的上下文向量开始，并生成输出序列。
   - 解码器也是一个RNN或Transformer网络。它在每一步生成当前输出的同时，将前一步的输出作为下一步的输入。因此，解码器是一个自回归模型。
3. **训练过程**
   - 在训练过程中，解码器每一步的输入并不是前一步预测的输出，而是正确的目标输出（即教师强制，Teacher Forcing）。这样可以加速训练并帮助模型更快地收敛。
4. **推理过程**
   - 在推理阶段，模型只能依赖前一步的预测作为下一步的输入。因此，解码器在推理过程中是通过逐步生成每一个输出。

### 注意力机制（Attention Mechanism）

传统的seq2seq模型在处理长序列时会遇到问题，因为编码器必须将整个输入序列压缩到一个固定大小的上下文向量中。为了解决这一问题，**注意力机制**被引入，它允许解码器在每一步生成输出时动态地选择输入序列中的哪些部分是最相关的。

- **注意力分布**：每个解码步骤生成一个权重分布，表示输入序列的不同部分对于当前解码步骤的重要性。
- **上下文向量更新**：上下文向量不再是静态的，而是根据解码步骤动态计算出来，结合了输入序列中的重要部分信息。

### Transformer与seq2seq

Transformer架构是一种更现代的seq2seq实现方式，完全抛弃了RNN结构，改用**自注意力机制**（Self-Attention）来处理输入和输出序列。Transformer结构提高了并行处理能力，并显著提升了长序列建模的效果。Google的BERT、GPT等模型就是基于这种结构。

### 适用场景

- **机器翻译**：将一句话从一种语言翻译到另一种语言。
- **文本摘要**：将长文档总结成简短摘要。
- **语音识别**：将语音输入转成文本输出。
- **对话生成**：基于输入对话生成合理的回答。

## 束搜索

束搜索是一种用于序列生成任务的解码算法，通常在生成模型（如机器翻译、文本生成、语音识别等）中使用。它的目的是尽可能寻找全局最优的输出序列，而不是像贪心搜索那样只在每一步选择当前最优解。相比贪心搜索，束搜索的核心在于：**每个时间步保留多个候选序列**，并在后续步骤中扩展这些候选序列，从而避免因为每一步局部最优选择而错过全局最优解。

### **工作原理**

束搜索的主要原理是通过每个时间步生成多个候选项，保持固定数量的候选序列，并在最后选择得分最高的序列。

#### **主要步骤**

1. **初始化**：从起始标记 `<START>` 开始，初始时只有一个候选序列，并且初始得分为0。
2. **扩展候选序列**：
   - 在每个时间步，模型预测当前候选序列的下一个可能输出（例如词或符号），并为每个可能的输出分配一个概率。
   - 计算新候选序列的总得分，通常取对数概率的和来避免概率值过小。
3. **筛选前 k 个候选**：
   - 根据得分对扩展出的所有候选序列进行排序，保留得分最高的 k 个候选序列（称为束宽，`beam width`）。
   - k 越大，表示保留的可能性越多，但计算复杂度也会增加。
4. **重复扩展**：
   - 重复上述步骤，直到所有候选序列生成结束标记 `<END>` 或达到预定的最大长度。
5. **最终输出**：
   - 解码结束后，从所有候选序列中选择得分最高的作为最终输出序列。

#### 长度惩罚

在束搜索中，较长的序列可能因为累积概率值更高而容易被优先选择。为了避免偏向较长的序列，常引入**长度惩罚**（Length Penalty）。长度惩罚会降低较长序列的得分，防止其在没有实际贡献的情况下被优先选择。

公式为：

$$
\text{adjusted score} = \frac{\text{original score}}{(5 + \text{sequence length})^\alpha}
$$
其中，$ \alpha $ 是长度惩罚的调节参数。通过调整$ \alpha $，可以控制对长序列的惩罚力度。

### **束宽（Beam Width）的影响**

- 束宽 k决定了每个时间步保留的候选序列数量：

   - **小束宽**：如 k=1 相当于贪心搜索，计算快但容易陷入局部最优。
- **大束宽**：如 k 很大时，可以保留更多候选路径，搜索更全面，但计算复杂度增高。

通常，k 的值在 3 到 10 之间可以在计算效率和搜索质量之间达到平衡。

### **优点与缺点**

#### **优点**：

- **避免局部最优解**：束搜索通过保留多个候选序列，能够避免贪心搜索陷入局部最优。
- **灵活调节**：通过调整束宽，可以在生成质量和计算开销之间找到平衡。

#### **缺点**：

- **计算复杂度高**：束宽越大，计算复杂度会随着时间步数呈指数级增长。
- **未必能找到全局最优解**：尽管保留了多个候选序列，但如果束宽较小，仍可能错过全局最优解。

### **总结**

束搜索是一种在序列生成任务中常用的解码算法，保留多个候选序列逐步扩展以生成最优结果。它比贪心搜索更全面，但也伴随着更高的计算复杂度。通过调整束宽，用户可以灵活控制搜索的深度和效率。

------

- LeNet（LeNet-5）：
  ![](.\KeyPoint.assets\image-20241019153759669.png)

- AlexNet：AlexNet和LeNet的设计理念非常相似，AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层，AlexNet使用ReLU而不是sigmoid作为其激活函数。从LeNet（左）到AlexNet（右）：
  ![](.\KeyPoint.assets\image-20241019154010562.png)

- VGG：虽然AlexNet证明深层神经网络卓有成效，但没有一个通用的模板来指导设计新的网络。于是使用块的VGG网络被提出。VGG-11使用可复用的卷积块构造网络。不同的VGG模型可通过每个块中卷积层数量和输出通道数量的差异来定义。块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。同时论文中发现深层且窄的卷积（即3×3）比较浅层且宽的卷积更有效。
  ![](.\KeyPoint.assets\image-20241019154646978.png)

-  网络中的网络（NiN）：LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征；然后通过全连接层对特征的表征进行处理。 AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。或者，可以想象在这个过程的早期使用全连接层。然而，如果使用了全连接层，可能会完全放弃表征的空间结构（进入全连接层之前会展开为一维）。 网络中的网络（NiN）提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机 。NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层。 如果我们将权重连接到每个空间位置，我们可以将其视为1×1卷积层，或作为在每个像素位置上独立作用的全连接层。 从另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）。
  ![](.\KeyPoint.assets\image-20241019160142362.png)

  1）NiN使用由一个卷积层和多个1×1卷积层组成的块。该块可以在卷积神经网络中使用，以允许更多的每像素非线性。2）NiN去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层（即在所有位置上进行求和）同时显著减少NiN的参数。3）NiN的设计影响了许多后续卷积神经网络的设计。

- 含并行连结的网络（GoogLeNet）：这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题。本文的一个观点是，有时使用不同大小的卷积核组合是有利的。在GoogLeNet中，基本的卷积块被称为*Inception块*（Inception block）：
  ![](.\KeyPoint.assets\image-20241019160905650.png)
  Inception块由四条并行路径组成。 前三条路径使用窗口大小为1×1、3×3和5×5的卷积层，从不同空间大小中提取信息。 中间的两条路径在输入上执行1×1卷积，以减少通道数，从而降低模型的复杂性。 第四条路径使用3×3最大汇聚层，然后使用1×1卷积层来改变通道数。 这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。
  GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值。Inception块之间的最大汇聚层可降低维度。 第一个模块类似于AlexNet和LeNet，Inception块的组合从VGG继承，全局平均汇聚层避免了在最后使用全连接层。
  ![](.\KeyPoint.assets\image-20241019161518963.png)
  1)Inception块相当于一个有4条路径的子网络，它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用1×1卷积层减少每像素级别上的通道维数从而降低模型复杂度。2)GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层)串联起来

- 训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手。*批量规范化*（batch normalization）是一种流行且有效的技术，可持续加速深层网络的收敛速度。通过在每个批次中标准化每一层的输入，使其均值为 0，方差为 1，从而稳定网络的输入分布。

- 残差网络（ResNet）：为了解决神经网络过深导致的梯度消失问题，ResNet巧妙地引入了残差结构。
  ![](.\KeyPoint.assets\image-20241019164612890.png)
  ResNet沿用了VGG完整的3×3卷积层设计。 残差块里首先有2个有相同输出通道数的3×3卷积层。 每个卷积层后接一个批量规范化层和ReLU激活函数。 然后我们通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的ReLU激活函数前。 这样的设计要求2个卷积层的输出与输入形状一样，从而使它们可以相加。 如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。
  ![](.\KeyPoint.assets\image-20241019164830501.png)
  1）学习嵌套函数（nested function）是训练神经网络的理想情况。2）利用残差块（residual blocks)可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播。3)残差网络（ResNet)对随后的深层神经网络设计产生了深远影响。

- 稠密连接网络（DenseNet）：在DenseNet中，每一层都与其他层相关联，这样的设计大大减轻了梯度消失的问题。稠密网络主要由2部分构成：*稠密块*（dense block）和*过渡层*（transition layer）。 前者定义如何连接输入和输出，而后者则控制通道数量，使其不会太复杂。1）一个*稠密块*由多个卷积块组成，每个卷积块使用相同数量的输出通道。 然而，在前向传播中，我们将每个卷积块的输入和输出在通道维上连结（每一层都与其他层相关联）。2）由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。 而过渡层可以用来控制模型复杂度。 它通过1×1卷积层来减小通道数，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度。
  ![](.\KeyPoint.assets\image-20241019171239214.png)

------



### R-CNN (Regions with Convolutional Neural Networks)

- **基本概念**：R-CNN 是一种目标检测方法，结合了选择性搜索（Selective Search）和卷积神经网络（CNN）。
- ![image-20241021151452360](.\KeyPoint.assets\image-20241021151452360.png)
- 步骤：
  1. **候选区域生成**：使用选择性搜索生成一系列可能的目标候选区域（region proposals）。
  2. **特征提取**：对每个候选区域使用 CNN 提取特征。由于候选区域具有不同大小和形状，会先将每个提议区域变形为网络需要的输入尺寸，再进行特征提取。
  3. **分类与回归**：使用多个支持向量机（SVM）分类每个候选区域，并使用线性回归调整边界框。
- **缺点**：由于每个候选区域都需要独立处理，计算量大且速度较慢。

### Fast R-CNN

- **基本概念**：Fast R-CNN 是对 R-CNN 的改进，优化了特征提取过程。Fast R-CNN 的关键改进之一是只对整张图像进行一次前向传播，提取全图的特征，从而共享计算资源。
- ![image-20241021151503007](.\KeyPoint.assets\image-20241021151503007.png)
- 步骤：
  1. **特征图生成**：对整张图像一次性通过 CNN 生成特征图。
  2. **候选区域生成**： 选择性搜索生成了多个提议区域。这些区域的形状各不相同，然后在特征图上映射出相应的兴趣区域。
  3. **区域池化**：使用 ROI Pooling 将候选区域映射到特征图上，得到固定大小的特征向量，便于连结后输出。
  4. **分类与回归**：通过全连接层对特征向量进行分类和边界框回归。
- **优点**：大大减少了计算时间，提高了速度。

### Faster R-CNN

- **基本概念**：Faster R-CNN 进一步优化了 Fast R-CNN，引入了区域提议网络（RPN）来生成候选区域，从而减少提议区域的生成数量，并保证目标检测的精度。
- ![image-20241021152914946](.\KeyPoint.assets\image-20241021152914946.png)
- 步骤：
  1. **特征图生成**：与 Fast R-CNN 相同，先通过 CNN 生成特征图。
  2. **区域提议网络**：在特征图上添加一个 RPN，负责生成高质量的候选区域。
  3. **ROI Pooling 和分类回归**：与 Fast R-CNN 类似，对 RPN 输出的候选区域进行 ROI Pooling，然后分类和回归。
- **优点**：RPN 使得候选区域生成过程更加高效，无需依赖选择性搜索。

### Mask R-CNN

- **基本概念**：Mask R-CNN 是在 Faster R-CNN 的基础上扩展而来，添加了实例分割的能力，并能够反过来提升CNN的性能。
- ![image-20241021153943819](.\KeyPoint.assets\image-20241021153943819.png)
- 步骤：
  1. **与 Faster R-CNN 类似**：生成特征图并使用 RPN 生成候选区域，但是将RoI pooling改为了RoI align，避免像素级上的偏移。
  2. **多任务学习**：在原有的分类和边界框回归任务之外，添加一个分支来生成每个实例的二进制掩膜（mask）。
  3. **掩膜生成**：通过全卷积网络（FCN）为每个候选区域生成对应的掩膜。
- **优点**：可以同时进行目标检测和实例分割，适用于需要识别和分割目标的任务。

------

### SSD (Single Shot MultiBox Detector)

SSD（单次多框检测器）是一种高效的目标检测算法，它在保持高准确度的同时，能够实现实时检测。SSD 的核心思想是通过**单次前向传播**，直接从图像中预测边界框和类别，显著减少了计算时间。

![image-20241021161546054](.\KeyPoint.assets\image-20241021161546054.png)

#### 主要特点

1. **单次检测**：
   - SSD 使用单一的卷积神经网络（CNN）在一个前向传播过程中同时预测多个边界框和类别，而不是像 R-CNN 系列方法那样依赖候选区域。
2. **多尺度特征**：
   - SSD 在不同的特征图上进行检测，这些特征图来源于网络的不同层次，从而能够捕捉到不同尺度的目标。这一多尺度策略使得 SSD 能够更有效地处理各种大小的目标。
3. **默认框（Default Boxes）**：
   - SSD 为**每个特征图的每个位置定义了一组预设的边界框**，称为默认框。这些框具有不同的长宽比和尺度，用于覆盖不同形状的物体。
4. **多任务学习**：
   - SSD 在每个特征图上同时进行边界框回归和类别预测。这种多任务学习方法使得模型能够同时优化位置和分类信息。

#### 工作流程

1. **特征提取**：
   - 输入图像经过卷积神经网络（如 VGG16、ResNet 等）进行特征提取，得到一系列特征图。
2. **默认框生成**：
   - 在每个特征图的每个位置，SSD 生成多个默认框。这些框的大小和比例经过精心设计，以覆盖可能出现的目标。
3. **边界框回归和分类**：
   - 对每个默认框，SSD 预测其与真实目标的偏差（边界框回归），并同时预测该框的类别分布（分类）。这个过程在每个特征图上进行，输出一个高维的预测结果。预测层的核心思想是使用卷积层的通道来输出类别预测或边界框预测。
4. **非极大值抑制（NMS）**：
   - 为了去除重复的预测框，SSD 在得到所有的预测框后，应用非极大值抑制算法，保留最有可能的边界框。

------

### YOLO（You Only Look Once）

YOLO（You Only Look Once）是一种实时目标检测系统，以其高效性和准确性而广受欢迎。与传统的目标检测方法不同，YOLO将目标检测视为一个回归问题，直接从整个图像预测边界框和类别概率。

#### 1. 工作原理

- **网络结构**： SSD中锚框大量重叠，因此浪费了很多计算。YOLO使用一个深度卷积神经网络（CNN）来提取图像特征，并将整个图像划分为一个网格（grid）。每个网格负责预测该区域内的目标。
- **预测**： 对于每个网格，YOLO预测固定数量的边界框（因为一个网格中可能有多个物体）和对应的置信度分数，置信度分数表示该边界框内存在目标的概率及其准确性。
- **类别预测**： 每个网格还会输出目标的类别概率分布，结合边界框的置信度，可以得到每个检测框的最终类别。

#### 2. 主要特点

- **实时性**： YOLO的设计旨在实现高效的推理速度，使其能够在视频流中实时检测目标。
- **全局上下文信息**： 由于YOLO在全图上进行检测，它能够更好地捕捉全局上下文信息，而不仅仅是关注局部区域。
- **端到端训练**： YOLO使用单个神经网络进行端到端训练，简化了训练过程，提高了模型的稳定性。

YOLO是一个创新的目标检测框架，通过将检测问题转化为回归问题，实现了高效和准确的实时目标检测。其多版本的演进不断提升了检测性能，使其在计算机视觉领域中占据了重要地位。

------

